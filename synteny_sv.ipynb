{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d482fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sys, os, psutil, io\n",
    "import gzip\n",
    "import time \n",
    "import warnings\n",
    "\n",
    "from pybedtools import BedTool\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb8faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path='/Users/shu/pollard_lab/atrt/'\n",
    "#annotated_del=pd.read_csv(data_path + '20230802_del_test_annotated.txt', sep='\\t')\n",
    "\n",
    "synteny_condensed=pd.read_csv('/pollard/home/shzhang/data/synteny/hg38_mm10_condensed.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b98d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "synteny_condensed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4971a419",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/pollard/data/projects/kgjoni/CBTN_collab/CBTN_data/'\n",
    "#simple_df=pd.read_csv(data_path + 'simple-variants_230620/simple_variants_all', sep='\\t')\n",
    "sv_df=pd.read_csv(data_path + 'structural-variants_230620/SVs_all', sep='\\t')\n",
    "sv_intra=sv_df[sv_df.SVTYPE != 'BND']\n",
    "sv_intra = sv_intra.reset_index(drop=True)\n",
    "sv_intra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeb08c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with chr len information\n",
    "chrom_len=pd.read_csv('/pollard/home/shzhang/akita_variant_scoring/data/chrom_lengths_hg38', sep='\\t', header=None)\n",
    "chrom_len[0]='chr' + chrom_len[0]\n",
    "sv_intra=sv_intra.merge(chrom_len, right_on=0, left_on='CHROM', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea763292",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7efbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALSO ADD BOUNDARIES FOR 1MB IN SV_INTRA\n",
    "\n",
    "\n",
    "sv_intra = sv_intra.rename(columns={1: 'chr_len'})\n",
    "sv_intra['half_len']=abs(sv_intra['END']-sv_intra['POS'])/2\n",
    "sv_intra['half_len']=np.minimum(sv_intra['half_len'], 5e5)\n",
    "\n",
    "sv_intra['POS_1MB']=np.floor(np.maximum(0, sv_intra['POS']-(5e5-sv_intra['half_len']) ))\n",
    "sv_intra['END_1MB']=np.floor(np.minimum(sv_intra['chr_len'], sv_intra['END']+ (5e5-sv_intra['half_len']) ))\n",
    "sv_intra['postoend_1mb']=sv_intra['END_1MB']-sv_intra['POS_1MB']\n",
    "sv_intra['postoend']=sv_intra['END']-sv_intra['POS']\n",
    "\n",
    "sv_intra=sv_intra[sv_intra.postoend<7e5]\n",
    "sv_intra = sv_intra.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fdc5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_intra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f5b73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "242893384.0-241893384.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68a5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 40)\n",
    "print(sv_intra[107:108]['INFO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4d932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(sv_intra.ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7077797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf5d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that lengths of seqs and alignments are correct  \n",
    "synteny_condensed['hg_dash_n']=synteny_condensed['hg_seq'].str.count('-')\n",
    "synteny_condensed['mm_dash_n']=synteny_condensed['mm_seq'].str.count('-')\n",
    "\n",
    "synteny_condensed['hg_percent']=1-(synteny_condensed['hg_dash_n']/synteny_condensed['total_align_len'])\n",
    "synteny_condensed['mm_percent']=1-(synteny_condensed['mm_dash_n']/synteny_condensed['total_align_len'])\n",
    "\n",
    "\n",
    "print(((synteny_condensed['hg_len'] + synteny_condensed['hg_dash_n']) == synteny_condensed['total_align_len']).all())\n",
    "print(((synteny_condensed['mm_len'] + synteny_condensed['mm_dash_n']) == synteny_condensed['total_align_len']).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8463e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(synteny_condensed['hg_percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01360d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68ce44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d2d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_intra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3213e3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants=sv_intra\n",
    "variants=variants[['CHROM', 'POS', 'END', 'ID']]\n",
    "variants['END']=variants['END'].astype(int)\n",
    "print(len(variants))\n",
    "variants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783d6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_1mb=sv_intra\n",
    "variants_1mb=variants_1mb[['CHROM', 'POS_1MB', 'END_1MB', 'ID']]\n",
    "variants_1mb['POS_1MB']=variants_1mb['POS_1MB'].astype(int)\n",
    "variants_1mb['END_1MB']=variants_1mb['END_1MB'].astype(int)\n",
    "print(len(variants_1mb))\n",
    "variants_1mb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d3665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_BED = BedTool.from_dataframe(variants)\n",
    "variant_1mb_BED = BedTool.from_dataframe(variants_1mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe31d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "synteny_BED = BedTool.from_dataframe(synteny_condensed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6482cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reports only SVs where there is overlap with  gene\n",
    "#-F ensures that at least 0.5 of gene has overlap with SV \n",
    "#use loj in this case, because many SVs overlap multiple syntenic regions  \n",
    "variant_synt=variant_BED.intersect(synteny_BED, loj=True, wo=True).to_dataframe(header=None)\n",
    "\n",
    "variant_1mb_synt=variant_1mb_BED.intersect(synteny_BED, loj=True, wo=True).to_dataframe(header=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e709fbd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d7622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_synt.columns = list(variants.columns) + list(synteny_condensed.columns)\n",
    "variant_synt = variant_synt[variant_synt['hg_chr'] != '.']\n",
    "print(len(variant_synt))\n",
    "variant_synt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c983178",
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_1mb_synt.columns = list(variants_1mb.columns) + list(synteny_condensed.columns)\n",
    "variant_1mb_synt = variant_1mb_synt[variant_1mb_synt['hg_chr'] != '.']\n",
    "print(len(variant_1mb_synt))\n",
    "variant_1mb_synt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd369dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(hg_seq, idx):\n",
    "    count_letters = 0  # To count the letters encountered in the combined string\n",
    "    idx_new = 0  # Corresponding index in combined string\n",
    "    \n",
    "    for char in hg_seq:\n",
    "        if count_letters == (idx+1):\n",
    "            break\n",
    "        if char.isalpha():\n",
    "            count_letters += 1\n",
    "        idx_new += 1\n",
    "    \n",
    "    return idx_new\n",
    "\n",
    "#given two aligned strings with start and end idx\n",
    "#count up amount of same characters within the alignment subset \n",
    "def count_str(hg_seq, mm_seq, start_idx, end_idx):\n",
    "    hg_subset = hg_seq[start_idx:end_idx]\n",
    "    mm_subset = mm_seq[start_idx:end_idx]\n",
    "\n",
    "    count_same = sum(1 for a, b in zip(hg_subset, mm_subset) if a == b)\n",
    "    prop=count_same/(end_idx-start_idx)\n",
    "    \n",
    "    \n",
    "    return(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a6d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST THAT THIS WORKS\n",
    "\n",
    "# Example strings\n",
    "hg_seq = \"a-t-t--gtc-aa\"\n",
    "idx = 3  # 0-indexed value\n",
    "\n",
    "# Find the corresponding index in the combined string\n",
    "corresponding_index = find_index(hg_seq, idx)\n",
    "print(\"Corresponding index:\", corresponding_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e603653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "for i in sv_intra.index:\n",
    "   \n",
    "    if i % 100 == 0:\n",
    "        print('index ', i)\n",
    "    \n",
    "    \n",
    "    #THIS ONE FOR 1MB SCORE \n",
    "    try:\n",
    "        #print(i)\n",
    "        variant=sv_intra.loc[i]\n",
    "        ID=variant.ID\n",
    "        int_df=variant_1mb_synt[variant_1mb_synt['ID'] == ID]\n",
    "\n",
    "        #print(len(int_df))\n",
    "    \n",
    "    \n",
    "        if len(int_df)>0:\n",
    "\n",
    "\n",
    "            int_df['start_idx']=(np.maximum(int_df['POS_1MB'], int_df['hg_start'])) - int_df['hg_start'] \n",
    "            int_df['end_idx']=(np.minimum(int_df['END_1MB'], int_df['hg_end'])) - int_df['hg_start'] \n",
    "            int_df['n_overlap']=int_df['end_idx']-int_df['start_idx']\n",
    "\n",
    "            \n",
    "            #get alignment indices\n",
    "            int_df['start_align_idx'] = int_df.apply(lambda row: find_index(row['hg_seq'], row['start_idx']), axis=1)\n",
    "            int_df['end_align_idx'] = int_df.apply(lambda row: find_index(row['hg_seq'], row['end_idx']), axis=1)\n",
    "            int_df['n_align_overlap']=int_df['end_align_idx']-int_df['start_align_idx']\n",
    "        \n",
    "        \n",
    "            int_df['count_prop'] = int_df.apply(lambda row: count_str(row['hg_seq'], row['mm_seq'],\n",
    "                                                                      row['start_align_idx'], row['end_align_idx']), axis=1)\n",
    "\n",
    "\n",
    "            #proportion of SV that covers a syntenic region  \n",
    "            sv_intra.loc[i, 'synt_prop_overlap_1MB'] = int(np.sum(int_df['n_overlap'])) /abs(sv_intra.loc[i, 'postoend_1mb'])\n",
    "            #weighted proportion of SV in syntenic region, and how similar those regions are \n",
    "            sv_intra.loc[i, 'align_synt_prop_1MB'] =  (np.sum(int_df['count_prop'] *int_df['n_overlap'])) /abs(sv_intra.loc[i, 'postoend_1mb'])\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            sv_intra.loc[i, 'synt_prop_overlap_1MB'] = 0\n",
    "            sv_intra.loc[i, 'align_synt_prop_1MB'] = 0\n",
    "            \n",
    "    except:\n",
    "        print('error in index', i)\n",
    "        \n",
    "        \n",
    "    #THIS ONE FOR NORMAL SV LENGTH \n",
    "    try:\n",
    "        #print(i)\n",
    "        variant=sv_intra.loc[i]\n",
    "        ID=variant.ID\n",
    "        int_df=variant_synt[variant_synt['ID'] == ID]\n",
    "        #print(len(int_df))\n",
    "    \n",
    "    \n",
    "        if len(int_df)>0:\n",
    "\n",
    "\n",
    "            int_df['start_idx']=(np.maximum(int_df['POS'], int_df['hg_start'])) - int_df['hg_start'] \n",
    "            int_df['end_idx']=(np.minimum(int_df['END'], int_df['hg_end'])) - int_df['hg_start'] \n",
    "            int_df['n_overlap']=int_df['end_idx']-int_df['start_idx']\n",
    "\n",
    "            \n",
    "            #get alignment indices\n",
    "            int_df['start_align_idx'] = int_df.apply(lambda row: find_index(row['hg_seq'], row['start_idx']), axis=1)\n",
    "            int_df['end_align_idx'] = int_df.apply(lambda row: find_index(row['hg_seq'], row['end_idx']), axis=1)\n",
    "            int_df['n_align_overlap']=int_df['end_align_idx']-int_df['start_align_idx']\n",
    "        \n",
    "        \n",
    "            int_df['count_prop'] = int_df.apply(lambda row: count_str(row['hg_seq'], row['mm_seq'],\n",
    "                                                                      row['start_align_idx'], row['end_align_idx']), axis=1)\n",
    "\n",
    "\n",
    "            #proportion of SV that covers a syntenic region  \n",
    "            sv_intra.loc[i, 'synt_prop_overlap'] = int(np.sum(int_df['n_overlap'])) /abs(sv_intra.loc[i, 'postoend'])\n",
    "            #weighted proportion of SV in syntenic region, and how similar those regions are \n",
    "            sv_intra.loc[i, 'align_synt_prop'] =  (np.sum(int_df['count_prop'] *int_df['n_overlap'])) /abs(sv_intra.loc[i, 'postoend'])\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            sv_intra.loc[i, 'synt_prop_overlap'] = 0\n",
    "            sv_intra.loc[i, 'align_synt_prop'] = 0\n",
    "            \n",
    "    except:\n",
    "        print('error 1mb in index', i)\n",
    "        \n",
    "        \n",
    "end=time.time()\n",
    "print(f\"Time taken: {end-start} seconds\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc3579",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_intra.to_csv('/pollard/home/shzhang/20231023_intra_sv_synteny_combined.txt', sep='\\t', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef529381",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_intra[1790:1800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95417b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS ONE IF ONLY THE NORMAL SV SCORES \n",
    "start=time.time()\n",
    "for i in sv_intra.index:\n",
    "   \n",
    "    if i % 100 == 0:\n",
    "        print('index ', i)\n",
    "    \n",
    "    try:\n",
    "        #print(i)\n",
    "        variant=sv_intra.loc[i]\n",
    "        ID=variant.ID\n",
    "        int_df=variant_synt[variant_synt['ID'] == ID]\n",
    "        #print(len(int_df))\n",
    "    \n",
    "    \n",
    "        if len(int_df)>0:\n",
    "\n",
    "\n",
    "            int_df['start_idx']=(np.maximum(int_df['POS'], int_df['hg_start'])) - int_df['hg_start'] \n",
    "            int_df['end_idx']=(np.minimum(int_df['END'], int_df['hg_end'])) - int_df['hg_start'] \n",
    "            int_df['n_overlap']=int_df['end_idx']-int_df['start_idx']\n",
    "\n",
    "            \n",
    "            #get alignment indices\n",
    "            int_df['start_align_idx'] = int_df.apply(lambda row: find_index(row['hg_seq'], row['start_idx']), axis=1)\n",
    "            int_df['end_align_idx'] = int_df.apply(lambda row: find_index(row['hg_seq'], row['end_idx']), axis=1)\n",
    "            int_df['n_align_overlap']=int_df['end_align_idx']-int_df['start_align_idx']\n",
    "        \n",
    "        \n",
    "            int_df['count_prop'] = int_df.apply(lambda row: count_str(row['hg_seq'], row['mm_seq'],\n",
    "\n",
    "            #proportion of SV that covers a syntenic region  \n",
    "            sv_intra.loc[i, 'synt_prop_overlap'] = int(np.sum(int_df['n_overlap'])) /abs(sv_intra.loc[i, 'SVLEN'])\n",
    "            #weighted proportion of SV in syntenic region, and how similar those regions are \n",
    "            sv_intra.loc[i, 'align_synt_prop'] =  (np.sum(int_df['count_prop'] *int_df['n_overlap'])) /abs(sv_intra.loc[i, 'SVLEN'])\n",
    "\n",
    "\n",
    "\n",
    "        else:\n",
    "            sv_intra.loc[i, 'synt_prop_overlap'] = 0\n",
    "            sv_intra.loc[i, 'align_synt_prop'] = 0\n",
    "            \n",
    "    except:\n",
    "        print('error in index', i)\n",
    "        \n",
    "        \n",
    "end=time.time()\n",
    "print(f\"Time taken: {end-start} seconds\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de2103",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_intra.to_csv('/pollard/home/shzhang/20231023_intra_sv_synteny_combined.txt', sep='\\t', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18acab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1=pd.read_csv('/pollard/home/shzhang/20230912_intra_sv_synteny.txt', sep='\\t')\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd681f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sv_intra.index:\n",
    "\n",
    "    #print(i)\n",
    "    variant=sv_intra.loc[i]\n",
    "    ID=variant.ID\n",
    "    int_df=variant_synt[variant_synt['ID'] == ID]\n",
    "    #print(len(int_df))\n",
    "    \n",
    "    \n",
    "    if len(int_df)>0:\n",
    "\n",
    "\n",
    "        int_df['start_idx']=(np.maximum(int_df['POS'], int_df['hg_start'])) - int_df['hg_start'] \n",
    "        int_df['end_idx']=(np.minimum(int_df['END'], int_df['hg_end'])) - int_df['hg_start'] \n",
    "        int_df['n_overlap']=int_df['end_idx']-int_df['start_idx']\n",
    "\n",
    "            \n",
    "        #get alignment indices\n",
    "        int_df['start_align_idx'] = int_df.apply(lambda row: find_index(row['hg_seq'], row['start_idx']), axis=1)\n",
    "        int_df['end_align_idx'] = int_df.apply(lambda row: find_index(row['hg_seq'], row['end_idx']), axis=1)\n",
    "        int_df['n_align_overlap']=int_df['end_align_idx']-int_df['start_align_idx']\n",
    "        \n",
    "        \n",
    "        int_df['count_prop'] = int_df.apply(lambda row: count_str(row['hg_seq'], row['mm_seq'],\n",
    "                                                                  row['start_align_idx'], row['end_align_idx']), axis=1)\n",
    "\n",
    "        #print(int_df)\n",
    "\n",
    "\n",
    "        #proportion of SV that covers a syntenic region  \n",
    "        sv_intra.loc[i, 'synt_prop_overlap'] = int(np.sum(int_df['n_overlap'])) /abs(sv_intra.loc[i, 'SVLEN'])\n",
    "        #weighted proportion of SV in syntenic region, and how similar those regions are \n",
    "        sv_intra.loc[i, 'align_synt_prop'] =  (np.sum(int_df['count_prop'] *int_df['n_overlap'])) /abs(sv_intra.loc[i, 'SVLEN'])\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        sv_intra.loc[i, 'synt_prop_overlap'] = 0\n",
    "        sv_intra.loc[i, 'align_synt_prop'] = 0\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f4f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "sv_intra.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d885e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at distritbution of synteny scores \n",
    "\n",
    "plt.scatter(annotated_del['synt_prop_overlap'], annotated_del['align_synt_prop'], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263316cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cases to consider\n",
    "#variant in no syntenic region \n",
    "# variant is fully in one syntenic region\n",
    "# variant partially in one syntenic region\n",
    "# variant in two or more syntenic regions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed7338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5a48f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
